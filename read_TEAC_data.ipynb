{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import taffmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_data_folder = \"F:/Dropbox/Projects/001 - CNRL - Pipewise/005 - Field Test/2023/data\"\n",
    "TEAC_raw_data_folder = parent_data_folder + \"/TEAC/Raw Data/\"\n",
    "TEAC_test_name = \"LX20_001\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_taffmat returns tuple containing three elements: a 2D NumPy array, a 1D NumPy array, and an OrderedDict with metadata\n",
    "test_raw_data = taffmat.read_taffmat(TEAC_raw_data_folder + TEAC_test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_channels = np.transpose(test_raw_data[0])\n",
    "#data_time = test_raw_data[1].reshape((len(test_raw_data[1]), 1)).reshape(-1, 1)\n",
    "data_combined = np.hstack((test_raw_data[1].reshape((len(test_raw_data[1]), 1)).reshape(-1, 1), np.transpose(test_raw_data[0])))\n",
    "\n",
    "# Clear memory\n",
    "del test_raw_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary from the arrays\n",
    "column_names = np.array(['time', 'CH1', 'CH2', 'CH3', 'CH4', 'CH5', 'CH6', 'CH7', 'CH8',\n",
    "                         'CH9', 'CH10', 'CH11', 'CH12', 'CH13', 'CH14', 'CH15', \n",
    "                         'CH16'])\n",
    "\n",
    "# Create a DataFrame from the numpy array with the specified column headers\n",
    "data_frame = pd.DataFrame(data_combined, columns=column_names)\n",
    "\n",
    "# Clear memory\n",
    "del data_combined"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum, minimums and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maximum, minimum, and average values\n",
    "max_values = data_frame.max()\n",
    "min_values = data_frame.min()\n",
    "average_values = data_frame.mean()\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "stats_df = pd.DataFrame({'Maximum': max_values, 'Minimum': min_values, 'Average': average_values})\n",
    "\n",
    "# Round the values to 1 decimal place\n",
    "stats_df_rounded = stats_df.round(1)\n",
    "\n",
    "# Display the results in a tabular format\n",
    "print(stats_df_rounded)\n",
    "\n",
    "# Note: values of 0.0 indicate that - most likely - the channel was not used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Points & Recording Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first column using its index and count the number of data points\n",
    "time_values = data_frame.iloc[:, 0]\n",
    "data_points_count = time_values.count()\n",
    "\n",
    "# Workaround to account for files that don't start at 0 seconds\n",
    "initial_recording_time = time_values.iloc[0]\n",
    "final_recording_time = time_values.iloc[-1]\n",
    "delta_recording_time = final_recording_time - initial_recording_time\n",
    "\n",
    "print(\"Number of data points in the first column:\", data_points_count)\n",
    "print(\"Data was recorded for\", round(delta_recording_time,2), \"seconds\")\n",
    "print(\"Data was recorded for\", round(delta_recording_time/60,2), \"minutes\")\n",
    "print(\"Data was recorded for\", round(delta_recording_time/3600,2), \"hours\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling rate, Consistency and CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time differences between consecutive data points\n",
    "time_differences = time_values.diff().dropna()\n",
    "\n",
    "# Define the expected sampling rate (in Hz) and maximum allowed deviation (in percentage)\n",
    "expected_sampling_rate = 12000  # Replace with your expected sampling rate\n",
    "max_allowed_deviation = 0.05  # 5% deviation, for example\n",
    "\n",
    "# Calculate the expected time difference between consecutive data points\n",
    "expected_time_difference = 1 / expected_sampling_rate\n",
    "\n",
    "# Calculate the deviation of each time difference from the expected time difference\n",
    "deviation = np.abs(time_differences - expected_time_difference)\n",
    "\n",
    "# Count the number of time intervals that exceed the maximum allowed deviation\n",
    "exceed_threshold_count = np.sum(deviation > max_allowed_deviation * expected_time_difference)\n",
    "\n",
    "# Calculate the percentage of time intervals that exceed the maximum allowed deviation\n",
    "exceed_threshold_percentage = exceed_threshold_count / len(time_differences) * 100\n",
    "\n",
    "# Calculate the effective sampling rate\n",
    "effective_sampling_rate = 1 / time_differences.mean()\n",
    "\n",
    "print(f\"Expected sampling rate: {expected_sampling_rate} Hz\")\n",
    "print(f\"Effective sampling rate: {effective_sampling_rate:.2f} Hz\")\n",
    "print(f\"Number of time intervals exceeding {max_allowed_deviation * 100}% deviation: {exceed_threshold_count}\")\n",
    "print(f\"Percentage of time intervals exceeding {max_allowed_deviation * 100}% deviation: {exceed_threshold_percentage:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots a single channel against time. Note: To plot a full test length takes a significant amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_values = data_frame.iloc[:, 0]\n",
    "device_data = data_frame[[\"CH16\"]]\n",
    "\n",
    "# Plot the first three columns with time_values as the x-axis\n",
    "for column in device_data.columns:\n",
    "    plt.plot(time_values, device_data[column], label=column)\n",
    "\n",
    "plt.xlim((100, 120))\n",
    "#plt.ylim((-10, 11))\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Value [V]')\n",
    "#plt.title('D1 Ch 0 - 2')\n",
    "plt.legend(device_data.columns, loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
